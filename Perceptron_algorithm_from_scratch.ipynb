{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMsFnlhH4q8Wy91liudTJ7z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elias-pitsi/machine_learning/blob/main/Perceptron_algorithm_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "kdUTTSEVq2mU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Perceptron:\n",
        "  def __init__(self, learning_rate=0.01, n_iters = 1000) -> None:\n",
        "    self.learning_rate = learning_rate\n",
        "    self.n_iters = n_iters\n",
        "    self.activation = self.activation_function\n",
        "    self.weights = None\n",
        "    self.bias = None\n",
        "\n",
        "\n",
        "  def activation_function(self, x):\n",
        "    return np.where(x >= 0, 1, 0)\n",
        "\n",
        "  def fit(self, X: np.ndarray, y):\n",
        "    n_samples, n_features = X.shape\n",
        "\n",
        "    # initialize parameters\n",
        "    self.weights = np.random.randn(n_features)\n",
        "    self.bias = 0\n",
        "\n",
        "    y_ = np.where(y>=0, 1, 0)\n",
        "\n",
        "    for _ in range(self.n_iters):\n",
        "      for idx, x_i in enumerate(X):\n",
        "        linear_output = np.dot(x_i, self.weights) + self.bias\n",
        "        y_pred = self.activation(linear_output)\n",
        "        update = self.learning_rate * (y_[idx] - y_pred)\n",
        "        self.weights += update * x_i\n",
        "        self.bias += update\n",
        "\n",
        "\n",
        "\n",
        "  def predict(self, X):\n",
        "    linear_output = np.dot(X, self.weights) + self.bias\n",
        "    y_pred = self.activation(linear_output)\n",
        "    return y_pred\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "vn-NMkBayzFh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dUGyFb0t2eID"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}